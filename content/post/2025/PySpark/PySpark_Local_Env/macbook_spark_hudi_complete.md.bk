# ğŸ macOS M3 æœ¬åœ° Apache Spark + Hudi + Hive Metastore + MinIO ç·´ç¿’ç’°å¢ƒ

é©ç”¨æ–¼ Macbook Pro M3 æ¶è¨­æœ¬åœ°ç·´ç¿’ç”¨ Data Lake ç’°å¢ƒï¼Œ
å¯ä½¿ç”¨ Spark å¯«å…¥ Hudi è‡³ MinIOï¼Œä¸¦åŒæ­¥ Hive Metastoreã€‚

---

## âœ… æ¶æ§‹èªªæ˜

```text
[Spark / PySpark]
     |
     | write Hudi table (s3a)
     v
[MinIO - S3A]  <------->  [Hive Metastore - thrift://localhost:9083]
                        |
                        v
                 [PostgreSQL Metadata]
```

## ğŸ“Š æ¶æ§‹åœ–ï¼ˆSpark + Hudi + MinIO + Hive Metastoreï¼‰

```mermaid
flowchart TB
    subgraph Spark
        A[Spark / PySpark]
    end

    subgraph S3[MinIO - s3a]
        B[Hudi è¡¨æ ¼]
    end

    subgraph HiveMetastore[Hive Metastore]
        C[Metastore Service\nthrift://localhost:9083]
        D[(PostgreSQL)]
    end

    A -->|write Hudi| B
    B -->|Hive sync| C
    C --> D
```

> ğŸ’¡ æ¶æ§‹ç¸½çµï¼šSpark å¯«å…¥ Hudi è¡¨æ ¼è‡³ MinIOï¼Œä¸¦é€é HMS (Hive Metastore Service) åŒæ­¥ metadata è‡³ PostgreSQLã€‚


---

## ğŸ”§ å®‰è£éœ€æ±‚

- Podman / podman-composeï¼ˆé€é `brew install` å®‰è£ï¼‰
- æœ¬æ©Ÿå·²å®‰è£ Spark & PySpark
- Python >= 3.9ï¼ˆåŸ·è¡Œ Notebook or pyspark scriptï¼‰

---

## ğŸªœ å•Ÿå‹•æµç¨‹

### 1. å•Ÿå‹•å®¹å™¨æœå‹™

```bash
chmod +x start.sh
./start.sh
```

- MinIO: `http://localhost:9001`ï¼ˆå¸³å¯†: minioadminï¼‰
- Hive Metastore: `thrift://localhost:9083`
- PostgreSQL: `localhost:5432`

---

### 2. Spark å»ºç«‹é€£ç·šè¨­å®šï¼ˆPySpark / Notebookï¼‰

```python
spark = SparkSession.builder \
    .appName("Spark-Hudi") \
    .config("spark.serializer", "org.apache.spark.serializer.KryoSerializer") \
    .config("spark.sql.catalogImplementation", "hive") \
    .config("spark.hadoop.hive.metastore.uris", "thrift://localhost:9083") \
    .config("spark.hadoop.fs.s3a.endpoint", "http://localhost:9000") \
    .config("spark.hadoop.fs.s3a.access.key", "minioadmin") \
    .config("spark.hadoop.fs.s3a.secret.key", "minioadmin") \
    .config("spark.hadoop.fs.s3a.path.style.access", "true") \
    .config("spark.hadoop.fs.s3a.impl", "org.apache.hadoop.fs.s3a.S3AFileSystem") \
    .enableHiveSupport() \
    .getOrCreate()
```

---

### 3. PySpark å¯«å…¥ Hudi ç¯„ä¾‹ï¼ˆä¸¦åŒæ­¥ Hiveï¼‰

```python
from pyspark.sql import Row
from pyspark.sql.functions import current_timestamp

data = [Row(id="1", name="Leonard"), Row(id="2", name="Yuki")]
df = spark.createDataFrame(data).withColumn("ts", current_timestamp())

df.write.format("hudi") \
    .option("hoodie.table.name", "demo_table") \
    .option("hoodie.datasource.write.recordkey.field", "id") \
    .option("hoodie.datasource.write.precombine.field", "ts") \
    .option("hoodie.datasource.write.operation", "insert") \
    .option("hoodie.datasource.hive_sync.enable", "true") \
    .option("hoodie.datasource.hive_sync.mode", "hms") \
    .option("hoodie.datasource.hive_sync.metastore.uris", "thrift://localhost:9083") \
    .option("hoodie.datasource.hive_sync.table", "demo_table") \
    .option("hoodie.datasource.hive_sync.database", "default") \
    .mode("overwrite") \
    .save("s3a://hudi/demo_table")
```

---


---

## ğŸ“¦ podman-compose.yml

```yaml
  pyspark:
    image: bitnami/spark:3.4
    container_name: pyspark
    environment:
      - SPARK_MODE=client
    ports:
      - "4040:4040"
    command: /opt/bitnami/scripts/spark/run.sh
    volumes:
      - ./:/app
    depends_on:
      - hive-metastore

version: '3'
services:
  minio:
    image: quay.io/minio/minio
    container_name: minio
    command: server /data --console-address ":9001"
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    volumes:
      - ./minio-data:/data

  postgres:
    image: postgres:14
    container_name: metastore_pg
    environment:
      POSTGRES_USER: hive
      POSTGRES_PASSWORD: hivepw
      POSTGRES_DB: metastore
    ports:
      - "5432:5432"
    volumes:
      - ./pgdata:/var/lib/postgresql/data

  hive-metastore:
    image: bitsondatadev/hive-metastore:3.1.3-postgresql
    container_name: hive_metastore
    depends_on:
      - postgres
    ports:
      - "9083:9083"
    environment:
      DB_DRIVER: org.postgresql.Driver
      SERVICE_JVM_HEAP: 2g
      METASTORE_DB_HOSTNAME: postgres
      METASTORE_DB_PORT: 5432
      METASTORE_DB_NAME: metastore
      METASTORE_DB_USER: hive
      METASTORE_DB_PASS: hivepw
    volumes:
      - ./hive-site.xml:/opt/hive/conf/hive-site.xml
```

> ğŸ³ ä½¿ç”¨å‰è«‹ç¢ºä¿ `podman-compose` æŒ‡ä»¤å¯ç”¨ï¼Œä¸” `start.sh` ä¸­æ­£ç¢ºå‘¼å«æœ¬æª”ã€‚



---

## ğŸš¦ Podman Compose å•Ÿå‹•æ³¨æ„äº‹é …

1. âœ… **å•Ÿå‹•é †åºæ³¨æ„**
   - é è¨­ `podman-compose up -d` æœƒè‡ªå‹•ä¾ç…§ `depends_on` å•Ÿå‹•é †åºï¼š
     - PostgreSQL â†’ Hive Metastore â†’ MinIO â†’ PySpark
   - å¦‚é‡ `metastore` å•Ÿå‹•éŒ¯èª¤ï¼Œè«‹å…ˆç¢ºèª PostgreSQL å¯æ­£ç¢ºå•Ÿå‹•ï¼ˆport 5432ï¼‰

2. ğŸ“‚ **ç¢ºèªä»¥ä¸‹ç›®éŒ„/æª”æ¡ˆå·²å»ºç«‹ï¼š**
   ```bash
   mkdir -p minio-data
   touch hive-site.xml  # ä¸¦æ­£ç¢ºå¡«å…¥ PostgreSQL èˆ‡ thrift ä½å€
   ```

3. ğŸ” **MinIO é è¨­å¸³å¯†**
   - `Access Key`: `minioadmin`
   - `Secret Key`: `minioadmin`
   - ç™»å…¥ç¶²å€ï¼š`http://localhost:9001`

4. ğŸ”Œ **Spark S3 è¨­å®šï¼ˆPySpark å®¹å™¨ï¼‰**
   - `s3a.endpoint`: `http://minio:9000`
   - `fs.s3a.path.style.access`: `true`

5. ğŸ **Hive Metastore thrift è¨­å®š**
   - URI: `thrift://hive_metastore:9083`
   - PostgreSQL: `jdbc:postgresql://metastore_pg:5432/metastore`
   - è‹¥ Metastore ç„¡æ³•å•Ÿå‹•è«‹æª¢æŸ¥ï¼š
     - PostgreSQL æ˜¯å¦å·²å•Ÿå‹•
     - hive-site.xml æ˜¯å¦ mount æ­£ç¢º

6. ğŸ§ª **é€²å…¥ pyspark å®¹å™¨æ¸¬è©¦**
   ```bash
   podman exec -it pyspark bash
   pyspark
   ```

7. ğŸ›‘ **é—œé–‰æ‰€æœ‰æœå‹™**
   ```bash
   podman-compose down
   ```

> ğŸ“ å»ºè­°åˆæ¬¡åŸ·è¡Œå…ˆä½¿ç”¨ `podman-compose up` è§€å¯Ÿ logï¼Œç¢ºä¿ PostgreSQL èˆ‡ Hive Metastore æ­£å¸¸å•Ÿå‹•ã€‚
## ğŸ“ å°ˆæ¡ˆæª”æ¡ˆèªªæ˜

| æª”æ¡ˆåç¨±            | åŠŸèƒ½æè¿°                             |
|---------------------|--------------------------------------|
| `podman-compose.yml`| å®šç¾© MinIO / PostgreSQL / Hive å®¹å™¨ |
| `start.sh`          | å¿«é€Ÿå•Ÿå‹•æŒ‡ä»¤                         |
| `hive-site.xml`     | Spark èªè­˜ Hive Metastore è¨­å®š       |
| `.gitignore`        | å¿½ç•¥å¿«å–èˆ‡æœ¬åœ°è³‡æ–™                   |
| `pyspark_hudi_demo.py` | å¯«å…¥ Hudi ä¸¦åŒæ­¥ Hive çš„ PySpark ç¯„ä¾‹ |

---

## ğŸ§¼ çµæŸèˆ‡æ¸…ç†

```bash
podman-compose down
rm -rf minio-data/ pgdata/
```

---

## ğŸ“˜ å‚™è¨»å»ºè­°

- å¯æ‰‹å‹•åœ¨ MinIO Console å»ºç«‹ bucket: `hudi`
- PostgreSQL ä½¿ç”¨è€…: `hive / hivepw`
- Hive Metastore é è¨­ DB: `metastore`
- å»ºè­°ç”¨ Spark 3.2+ + Hudi 0.12+

---

> ğŸ“… æ–‡ä»¶æœ€å¾Œæ›´æ–°ï¼š{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}ï¼ˆLeonard ä½¿ç”¨æ–¼ macOS M3ï¼‰

---

## ğŸ›  è‡ªè¨‚ Hive CLI æ¸¬è©¦å®¹å™¨

```dockerfile
# ç°¡æ˜“è‡ªå®šç¾© Hive Client å®¹å™¨ï¼Œå¯é€£ç·šåˆ° Metastore
FROM openjdk:11

RUN apt-get update && \
    apt-get install -y wget netcat && \
    wget https://downloads.apache.org/hive/hive-3.1.3/apache-hive-3.1.3-bin.tar.gz && \
    tar -xzf apache-hive-3.1.3-bin.tar.gz && \
    mv apache-hive-3.1.3-bin /opt/hive && \
    rm apache-hive-3.1.3-bin.tar.gz

ENV HIVE_HOME=/opt/hive
ENV PATH=$HIVE_HOME/bin:$PATH

WORKDIR /opt/hive
```

å•Ÿå‹•å»ºè­°ï¼š

```bash
chmod +x build.sh
./build.sh
podman run -it --rm --network host hive-client hive --service cli
```

> â˜‘ å¯ç”¨æ–¼æ‰‹å‹•æ¸¬è©¦ Hive Metastore æ˜¯å¦æ­£ç¢ºå•Ÿå‹•èˆ‡åŒæ­¥ã€‚

---

## ğŸ§¾ hive-site.xml ç¯„ä¾‹

```xml
<?xml version="1.0"?>
<configuration>
    <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:postgresql://metastore_pg:5432/metastore</value>
        <description>PostgreSQL JDBC connection string</description>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>org.postgresql.Driver</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>hive</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionPassword</name>
        <value>hivepw</value>
    </property>
    <property>
        <name>datanucleus.autoCreateSchema</name>
        <value>false</value>
    </property>
    <property>
        <name>datanucleus.fixedDatastore</name>
        <value>true</value>
    </property>
    <property>
        <name>datanucleus.autoCreateTables</name>
        <value>false</value>
    </property>
    <property>
        <name>hive.metastore.uris</name>
        <value>thrift://hive_metastore:9083</value>
    </property>
</configuration>
```

---

## ğŸ©º å®¹å™¨å¥åº·æª¢æŸ¥è…³æœ¬ healthcheck.sh

```bash
#!/bin/bash

echo "ğŸ©º Checking container health status..."

containers=(minio metastore_pg hive_metastore pyspark)

for container in "${containers[@]}"; do
  echo -n "ğŸ” $container: "
  podman inspect --format='{{.State.Status}}' "$container"
done

echo ""
echo "ğŸŒ Verifying Hive Metastore port:"
nc -zv localhost 9083 || echo "âŒ Hive Metastore port 9083 unreachable"

echo "ğŸŒ Verifying PostgreSQL port:"
nc -zv localhost 5432 || echo "âŒ PostgreSQL port 5432 unreachable"

echo "ğŸŒ Verifying MinIO port:"
nc -zv localhost 9000 || echo "âŒ MinIO port 9000 unreachable"
```
