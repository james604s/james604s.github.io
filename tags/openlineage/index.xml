<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Openlineage on KageNoLeonard</title><link>https://www.noleonardblog.com/tags/openlineage/</link><description>Recent content in Openlineage on KageNoLeonard</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 27 Sep 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://www.noleonardblog.com/tags/openlineage/index.xml" rel="self" type="application/rss+xml"/><item><title>PySpark 學習筆記 - Data Lineage with Datahub</title><link>https://www.noleonardblog.com/p/pyspark_lineage_with_datahub/</link><pubDate>Sat, 27 Sep 2025 00:00:00 +0000</pubDate><guid>https://www.noleonardblog.com/p/pyspark_lineage_with_datahub/</guid><description>&lt;h1 id="pyspark-data-lineage-with-datahub"&gt;PySpark Data Lineage with Datahub
&lt;/h1&gt;&lt;p&gt;在我們日常的資料工作中，一個最令人頭痛的問題莫過於：「這張報表的資料到底從哪裡來？中間經過了哪些處理？」當資料流程變得越來越複雜時，如果沒有清晰的&lt;strong&gt;資料血緣 (Data Lineage)&lt;/strong&gt;，追蹤問題、評估變更影響，甚至確保資料的可信度，都會變成一場噩夢。&lt;/p&gt;
&lt;p&gt;幸運的是，像 PySpark 這樣的強大處理引擎，搭配 Datahub 這樣的現代資料目錄 (Data Catalog)，可以幫助我們自動化地解開這個謎團。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;在 Datahub 中呈現的清晰資料血緣圖&lt;/em&gt;&lt;/p&gt;
&lt;h2 id="spark--lineage"&gt;&lt;strong&gt;Spark &amp;amp; Lineage&lt;/strong&gt;
&lt;/h2&gt;&lt;p&gt;在我們動手寫任何程式碼之前，最重要的一步是理解這背後的「魔法」是如何運作的。PySpark 本身並不會主動告訴外界它的資料流向，那麼 Datahub 是如何得知的呢？&lt;/p&gt;
&lt;p&gt;答案就在於 Spark 提供的一個強大機制：&lt;strong&gt;SparkListener&lt;/strong&gt; 介面。&lt;/p&gt;
&lt;h3 id="sparklistener安插在-spark-內的事件監聽器"&gt;&lt;strong&gt;SparkListener：安插在 Spark 內的事件監聽器&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;SparkListener 是 Spark 框架中基於觀察者模式 (Observer Pattern) 的一個實作。你可以把它想像成一個我們安插在 Spark 應用程式內部的「事件監聽器」。當你的 PySpark 腳本執行時，它內部的每一個重要動作——作業開始 (onJobStart)、作業結束 (onJobEnd)，乃至於一個查詢的執行 (onQueryExecution)——都會在 Spark 內部觸發一個對應的「事件」。&lt;/p&gt;
&lt;p&gt;我們的血緣擷取工具，正是透過實作這個介面來監聽這些事件。其中，對於資料血緣來說，最重要的事件是 &lt;strong&gt;onQueryExecution&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id="logical-planspark-任務的原始設計藍圖"&gt;&lt;strong&gt;Logical Plan：Spark 任務的原始設計藍圖&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;當 onQueryExecution 事件被觸發時，監聽器會收到一個 QueryExecution 物件，這個物件中包含了我們擷取血緣的關鍵資訊：&lt;strong&gt;邏輯計劃 (Logical Plan)&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;Logical Plan 是一個抽象語法樹 (Abstract Syntax Tree, AST)，它代表了你的 DataFrame 操作或 SQL 查詢在經過任何優化&lt;strong&gt;之前&lt;/strong&gt;的完整結構。為什麼強調「未經優化」？因為它最忠實地反映了你編寫的程式碼邏輯。這個計畫詳細記錄了：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;資料來源 (Sources)&lt;/strong&gt;：透過 UnresolvedRelation 等節點，標示資料是從哪個資料庫的哪張表讀取的。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;轉換操作 (Transformations)&lt;/strong&gt;：透過 Project (對應 select 或 withColumn)、Filter、Join 等節點，描述資料經過的每一個處理步驟。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;資料去向 (Sink)&lt;/strong&gt;：描述最終結果被寫入到哪個目的地。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;血緣工具的核心任務，就是遞迴地遍歷這棵 Logical Plan 樹，解析出其中包含的輸入、輸出以及欄位級別的操作，從而完整地還原出資料的完整旅程。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;核心概念&lt;/strong&gt;：無論是 Datahub 的原生整合工具，還是 OpenLineage 的開放標準工具，它們的核心都是實現了一個 SparkListener。&lt;strong&gt;它們的根本差異，不在於如何擷取 Logical Plan，而在於如何將解析後的血緣資訊「格式化」並「匯報」給 Datahub。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id="etl-example-部分由-gemini-生成"&gt;&lt;strong&gt;ETL Example (部分由 Gemini 生成)&lt;/strong&gt;
&lt;/h2&gt;&lt;p&gt;理論講完了，讓我們來建立一個統一的實戰場景。以下是一個通用的 PySpark 腳本，它將是我們後續兩種方法的測試對象。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;任務目標&lt;/strong&gt;：從 MSSQL 的 dbo.source_table 讀取資料，進行一系列轉換，然後將結果寫入 dbo.target_table。&lt;/p&gt;
&lt;h3 id="process_mssql_datapy"&gt;process_mssql_data.py
&lt;/h3&gt;&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt; 1
&lt;/span&gt;&lt;span class="lnt"&gt; 2
&lt;/span&gt;&lt;span class="lnt"&gt; 3
&lt;/span&gt;&lt;span class="lnt"&gt; 4
&lt;/span&gt;&lt;span class="lnt"&gt; 5
&lt;/span&gt;&lt;span class="lnt"&gt; 6
&lt;/span&gt;&lt;span class="lnt"&gt; 7
&lt;/span&gt;&lt;span class="lnt"&gt; 8
&lt;/span&gt;&lt;span class="lnt"&gt; 9
&lt;/span&gt;&lt;span class="lnt"&gt;10
&lt;/span&gt;&lt;span class="lnt"&gt;11
&lt;/span&gt;&lt;span class="lnt"&gt;12
&lt;/span&gt;&lt;span class="lnt"&gt;13
&lt;/span&gt;&lt;span class="lnt"&gt;14
&lt;/span&gt;&lt;span class="lnt"&gt;15
&lt;/span&gt;&lt;span class="lnt"&gt;16
&lt;/span&gt;&lt;span class="lnt"&gt;17
&lt;/span&gt;&lt;span class="lnt"&gt;18
&lt;/span&gt;&lt;span class="lnt"&gt;19
&lt;/span&gt;&lt;span class="lnt"&gt;20
&lt;/span&gt;&lt;span class="lnt"&gt;21
&lt;/span&gt;&lt;span class="lnt"&gt;22
&lt;/span&gt;&lt;span class="lnt"&gt;23
&lt;/span&gt;&lt;span class="lnt"&gt;24
&lt;/span&gt;&lt;span class="lnt"&gt;25
&lt;/span&gt;&lt;span class="lnt"&gt;26
&lt;/span&gt;&lt;span class="lnt"&gt;27
&lt;/span&gt;&lt;span class="lnt"&gt;28
&lt;/span&gt;&lt;span class="lnt"&gt;29
&lt;/span&gt;&lt;span class="lnt"&gt;30
&lt;/span&gt;&lt;span class="lnt"&gt;31
&lt;/span&gt;&lt;span class="lnt"&gt;32
&lt;/span&gt;&lt;span class="lnt"&gt;33
&lt;/span&gt;&lt;span class="lnt"&gt;34
&lt;/span&gt;&lt;span class="lnt"&gt;35
&lt;/span&gt;&lt;span class="lnt"&gt;36
&lt;/span&gt;&lt;span class="lnt"&gt;37
&lt;/span&gt;&lt;span class="lnt"&gt;38
&lt;/span&gt;&lt;span class="lnt"&gt;39
&lt;/span&gt;&lt;span class="lnt"&gt;40
&lt;/span&gt;&lt;span class="lnt"&gt;41
&lt;/span&gt;&lt;span class="lnt"&gt;42
&lt;/span&gt;&lt;span class="lnt"&gt;43
&lt;/span&gt;&lt;span class="lnt"&gt;44
&lt;/span&gt;&lt;span class="lnt"&gt;45
&lt;/span&gt;&lt;span class="lnt"&gt;46
&lt;/span&gt;&lt;span class="lnt"&gt;47
&lt;/span&gt;&lt;span class="lnt"&gt;48
&lt;/span&gt;&lt;span class="lnt"&gt;49
&lt;/span&gt;&lt;span class="lnt"&gt;50
&lt;/span&gt;&lt;span class="lnt"&gt;51
&lt;/span&gt;&lt;span class="lnt"&gt;52
&lt;/span&gt;&lt;span class="lnt"&gt;53
&lt;/span&gt;&lt;span class="lnt"&gt;54
&lt;/span&gt;&lt;span class="lnt"&gt;55
&lt;/span&gt;&lt;span class="lnt"&gt;56
&lt;/span&gt;&lt;span class="lnt"&gt;57
&lt;/span&gt;&lt;span class="lnt"&gt;58
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-fallback" data-lang="fallback"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;from pyspark.sql import SparkSession
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;from pyspark.sql.functions import col, lit, current_timestamp, upper, year, month
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;def main():
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; 一個從 MSSQL 讀取、轉換並寫入的 Spark ETL 作業。
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; spark = SparkSession.builder.appName(&amp;#34;MSSQL_ETL_Lineage_Demo&amp;#34;).getOrCreate()
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; # db conn
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; jdbc_url = &amp;#34;jdbc:sqlserver://your_mssql_server:1433;databaseName=your_db&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; connection_properties = {
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &amp;#34;user&amp;#34;: &amp;#34;your_user&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &amp;#34;password&amp;#34;: &amp;#34;your_password&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &amp;#34;driver&amp;#34;: &amp;#34;com.microsoft.sqlserver.jdbc.SQLServerDriver&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; }
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; source_table = &amp;#34;dbo.source_table&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; target_table = &amp;#34;dbo.target_table&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; # Read Table
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; print(&amp;#34;--- 正在從來源資料表讀取資料 ---&amp;#34;)
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; source_df = spark.read.jdbc(
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; url=jdbc_url,
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; table=source_table,
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; properties=connection_properties
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; )
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; print(&amp;#34;來源 DataFrame Schema:&amp;#34;)
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; source_df.printSchema()
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; # Tranform
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; print(&amp;#34;--- 正在進行資料轉換 ---&amp;#34;)
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; transformed_df = source_df \
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; .withColumn(&amp;#34;processed_at&amp;#34;, current_timestamp()) \
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; .withColumn(&amp;#34;job_name&amp;#34;, lit(&amp;#34;MSSQL_ETL_Lineage_Demo&amp;#34;)) \
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; .withColumn(&amp;#34;source_system_upper&amp;#34;, upper(col(&amp;#34;source_system&amp;#34;))) \
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; .withColumn(&amp;#34;event_year&amp;#34;, year(col(&amp;#34;event_date&amp;#34;))) \
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; .withColumn(&amp;#34;event_month&amp;#34;, month(col(&amp;#34;event_date&amp;#34;))) \
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; .filter(col(&amp;#34;value&amp;#34;) &amp;gt; 100)
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; print(&amp;#34;轉換後 DataFrame Schema:&amp;#34;)
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; transformed_df.printSchema()
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; # Write
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; print(f&amp;#34;--- 正在將資料寫入 {target_table} ---&amp;#34;)
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; transformed_df.write.jdbc(
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; url=jdbc_url,
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; table=target_table,
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; mode=&amp;#34;overwrite&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; properties=connection_properties
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; )
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; print(&amp;#34;--- 作業成功完成！ ---&amp;#34;)
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; spark.stop()
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;if __name__ == &amp;#34;__main__&amp;#34;:
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; main()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;現在，我們將用兩種不同的 spark-submit 指令來執行同一個腳本，看看它們是如何實現血緣追蹤的。&lt;/p&gt;
&lt;h3 id="路徑-a直達車---datahub-原生整合-acryl-spark-lineage"&gt;&lt;strong&gt;路徑 A：直達車 - Datahub 原生整合 (acryl-spark-lineage)&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;這條路徑像是搭乘一班為 Datahub 量身打造的直達專車，簡單、快速，改造 OpenLineage 標準以符合 Datahub 的格式。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;報告格式&lt;/strong&gt;：將 Logical Plan 直接翻譯成 Datahub 內部能理解的格式，稱為 &lt;strong&gt;Metadata Change Proposals (MCPs)&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;報告機制&lt;/strong&gt;：透過 HTTP API 直接將這些 MCPs 發送給 Datahub 的核心服務 (GMS)。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;確保你已經下載了 MSSQL JDBC 驅動&lt;/p&gt;&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-gdscript3" data-lang="gdscript3"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;export&lt;/span&gt; &lt;span class="n"&gt;MSSQL_JDBC_JAR&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;#34;/path/to/mssql-jdbc.jar&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;spark-submit 指令：&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;span class="lnt"&gt;2
&lt;/span&gt;&lt;span class="lnt"&gt;3
&lt;/span&gt;&lt;span class="lnt"&gt;4
&lt;/span&gt;&lt;span class="lnt"&gt;5
&lt;/span&gt;&lt;span class="lnt"&gt;6
&lt;/span&gt;&lt;span class="lnt"&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-fallback" data-lang="fallback"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;spark-submit \
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; --master local[*] \
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; --packages io.acryl:acryl-spark-lineage_2.12:0.2.18 \
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; --jars ${MSSQL_JDBC_JAR} \
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; --conf &amp;#34;spark.extraListeners=io.acryl.spark.AcrylSparkListener&amp;#34; \
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; --conf &amp;#34;spark.datahub.url=http://your-datahub-gms-host:8080&amp;#34; \
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; --conf &amp;#34;spark.datahub.token=YOUR_DATAHUB_API_TOKEN&amp;#34; \
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-fallback" data-lang="fallback"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;process_mssql_data.py
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;spark.extraListeners&lt;/strong&gt;: 這是啟動魔法的關鍵，告訴 Spark 要掛載 Acryl 的監聽器。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;spark.datahub.url&lt;/strong&gt;: Datahub GMS 服務的端點 (Endpoint)。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="路徑-b自由行---openlineage-開放標準"&gt;路徑 B：自由行 - OpenLineage 開放標準
&lt;/h3&gt;&lt;p&gt;這條路徑採用了 OpenLineage 這個開放標準，提供了更大的靈活性和未來擴充性。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;報告格式&lt;/strong&gt;：將 Logical Plan 翻譯成一種通用的、標準化的 &lt;strong&gt;OpenLineage Event (JSON 格式)&lt;/strong&gt;。這份「報告」任何支援 OpenLineage 的平台都看得懂。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;報告機制&lt;/strong&gt;：將標準化的 JSON 事件發送到一個指定的 HTTP 端點。Datahub 恰好提供了一個這樣的端點來接收這些事件。&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-gdscript3" data-lang="gdscript3"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;export&lt;/span&gt; &lt;span class="n"&gt;MSSQL&lt;/span&gt;\&lt;span class="n"&gt;_JDBC&lt;/span&gt;\&lt;span class="n"&gt;_JAR&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;#34;/path/to/mssql-jdbc.jar&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;spark-submit 指令：&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;span class="lnt"&gt;2
&lt;/span&gt;&lt;span class="lnt"&gt;3
&lt;/span&gt;&lt;span class="lnt"&gt;4
&lt;/span&gt;&lt;span class="lnt"&gt;5
&lt;/span&gt;&lt;span class="lnt"&gt;6
&lt;/span&gt;&lt;span class="lnt"&gt;7
&lt;/span&gt;&lt;span class="lnt"&gt;8
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-fallback" data-lang="fallback"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;spark-submit \
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; --master local[*] \
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; --packages io.openlineage:openlineage-spark:1.13.0 \
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; --jars ${MSSQL_JDBC_JAR} \
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; --conf &amp;#34;spark.extraListeners=io.openlineage.spark.agent.OpenLineageSparkListener&amp;#34; \
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; --conf &amp;#34;spark.openlineage.transport.type=http&amp;#34; \
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; --conf &amp;#34;spark.openlineage.transport.url=http://your-datahub-gms-host:8080/api/v1/lineage&amp;#34; \
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; --conf &amp;#34;spark.openlineage.namespace=my_production_etl&amp;#34; \
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-fallback" data-lang="fallback"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;process_mssql_data.py
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;spark.openlineage.transport.url&lt;/strong&gt;: 設定接收端點，注意！這裡指向的是 &lt;strong&gt;Datahub 專門用來接收 OpenLineage 事件的 API 端點&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如以上都執行成功，預計可以抓到資料血緣 (Table to Table)、(Column to Column)，
建議可以 Dev 期間可以先透過 Jupyter Notebook 一行執行，
Prod 再進行 Spark Submit。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://www.noleonardblog.com/p/pyspark_lineage_with_datahub/example.jpg"
width="1293"
height="908"
srcset="https://www.noleonardblog.com/p/pyspark_lineage_with_datahub/example_hu_b6661399be5b716c.jpg 480w, https://www.noleonardblog.com/p/pyspark_lineage_with_datahub/example_hu_2dfd3e35bf8146cb.jpg 1024w"
loading="lazy"
alt="PySpark Lineage"
class="gallery-image"
data-flex-grow="142"
data-flex-basis="341px"
&gt;&lt;/p&gt;
&lt;h2 id="summary"&gt;Summary
&lt;/h2&gt;&lt;p&gt;文章中探討了如何透過 PySpark 自動化地將資料血緣傳送到 Datahub。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;核心問題&lt;/strong&gt;：複雜的資料流程導致可觀測性 (Observability) 低落，難以追蹤和管理。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;解決方案&lt;/strong&gt;：利用 Spark 內建的 SparkListener 機制，在執行期間擷取 Logical Plan，從而自動生成血緣關係。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;兩種實現路徑&lt;/strong&gt;：
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Datahub 原生整合 (acryl-spark-lineage)&lt;/strong&gt;：最簡單、最直接的方法，專為 Datahub 設計，適合追求快速實施且技術棧單一的團隊。目前功能上整合越來越多 OpenLineage 的 Feature 做使用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OpenLineage 開放標準&lt;/strong&gt;：更具靈活性和擴充性的方法，它將血緣資訊標準化，使你的架構不受特定廠商綁定，是建立企業級、可持續演進資料平台的首選。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;如何選擇？&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;特性&lt;/th&gt;
&lt;th&gt;Datahub 原生整合 (路徑 A)&lt;/th&gt;
&lt;th&gt;OpenLineage 標準 (路徑 B)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;設定難度&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;⭐ (極簡)&lt;/td&gt;
&lt;td&gt;⭐⭐ (稍有門檻)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;廠商中立性&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;❌ (綁定 Datahub)&lt;/td&gt;
&lt;td&gt;✅ (可發送到任何相容後端)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;除錯能力&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;⭐⭐ (中等)&lt;/td&gt;
&lt;td&gt;⭐⭐⭐⭐⭐ (極佳，可直接查看事件內容)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;長期架構&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;適合單一平台、快速實施&lt;/td&gt;
&lt;td&gt;適合企業級、可持續演進的平台&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id="reference"&gt;Reference
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Datahub Native Integration&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class="link" href="https://docs.datahub.com/docs/metadata-integration/java/acryl-spark-lineage" target="_blank" rel="noopener"
&gt;Official Datahub Spark Lineage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="link" href="https://github.com/acryldata/acryl-spark-lineage" target="_blank" rel="noopener"
&gt;GitHub: acryl-spark-lineage&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OpenLineage Standard&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class="link" href="https://openlineage.io/" target="_blank" rel="noopener"
&gt;Official OpenLineage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="link" href="https://openlineage.io/docs/integrations/spark/" target="_blank" rel="noopener"
&gt;OpenLineage Spark Integration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="link" href="https://github.com/OpenLineage/OpenLineage/tree/main/integration/spark" target="_blank" rel="noopener"
&gt;GitHub: openlineage-spark&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</description></item></channel></rss>